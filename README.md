# Crypto Regulatory Tracker

Automated weekly crypto regulatory intelligence pipeline for compliance teams. Real-time monitoring across 5 major jurisdictions with AI-powered impact assessment and beautiful analytics dashboard.

## âœ¨ Features

### ğŸ“Š Web Dashboard (NEW!)
- **Real-time Analytics**: Interactive charts showing events by jurisdiction, impact, and category
- **Event Feed**: Filterable list of regulatory events with rich metadata
- **Impact Indicators**: Color-coded high/medium/low impact ratings
- **Responsive Design**: Works beautifully on desktop, tablet, and mobile
- **Demo Mode**: Pre-loaded with sample data for instant preview

### ğŸ¤– Automation Pipeline
- **5 Jurisdiction Coverage**: SEC (US), ESMA (EU), MAS (Singapore), JFSA (Japan), VARA (Dubai)
- **Smart Filtering**: Keyword + LLM classification to identify crypto-related updates
- **Impact Rating**: High/Medium/Low impact assessment via Claude Haiku
- **Weekly Reports**: Auto-generated newsletter-style digest
- **Email Delivery**: Resend integration for subscriber management

## ğŸš€ Quick Start

### Web Dashboard (Instant Demo)

```bash
# Install dependencies (one-time)
npm install

# Launch demo dashboard
npm run demo
```

Opens http://localhost:8080 with a beautiful dashboard showing sample regulatory events, analytics charts, and filtering.

**Perfect for:**
- Investor demos
- Product pitches
- User testing
- Understanding the data model

### Automation Pipeline

```bash
# Copy environment template
cp .env.example .env
# Edit .env with your credentials

# Run scraper (works without credentials - outputs to console)
npm run scrape

# Run full pipeline
npm run dev pipeline
```

## Commands

```bash
npm run scrape        # Fetch from all sources
npm run dev scrape    # Same as above
npm run dev classify  # LLM classification (needs ANTHROPIC_API_KEY)
npm run dev report    # Generate weekly report
npm run dev send <email>  # Send test email
npm run dev pipeline  # Full pipeline: scrape â†’ classify â†’ report
```

## Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `SUPABASE_URL` | Supabase project URL | For persistence |
| `SUPABASE_ANON_KEY` | Supabase anon key | For persistence |
| `ANTHROPIC_API_KEY` | Claude API key | For LLM classification |
| `RESEND_API_KEY` | Resend API key | For email delivery |
| `FROM_EMAIL` | Sender email address | For email delivery |

## Database Setup

1. Create a Supabase project at [supabase.com](https://supabase.com)
2. Run the schema in `sql/schema.sql` via SQL Editor
3. Copy project URL and anon key to `.env`

## Data Sources

| Source | Method | Status | Notes |
|--------|--------|--------|-------|
| SEC (US) | RSS | âœ… Working | Press releases work, Litigation blocked (403) |
| ESMA (EU) | RSS + HTML | âœ… Working | RSS blocked, HTML fallback works |
| MAS (Singapore) | RSS + Puppeteer | âœ… Working | Browser fallback for JS-rendered content |
| JFSA (Japan) | HTML scrape | âœ… Working | Low volume, keyword filtering |
| VARA (Dubai) | HTML + Puppeteer | âœ… Working | Browser fallback, 21 crypto items |

**All 5 sources functional!** Browser fallback automatically activates for JS-rendered sites.

## Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scrape    â”‚ â”€â”€â–º â”‚  Classify   â”‚ â”€â”€â–º â”‚   Report    â”‚ â”€â”€â–º â”‚    Send     â”‚
â”‚  (5 sources)â”‚     â”‚ (Claude AI) â”‚     â”‚  (Markdown) â”‚     â”‚  (Resend)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸŒ Deploying the Dashboard

The web dashboard is a static site in the `public/` folder. Deploy options:

### GitHub Pages (Recommended)
```bash
# Enable GitHub Pages in repo settings â†’ Pages â†’ Source: main branch /public folder
# Your dashboard will be live at: https://username.github.io/crypto-regulatory-tracker/
```

### Vercel / Netlify
```bash
# Deploy the public/ folder
# Build command: (none - static site)
# Publish directory: public
```

### Anywhere with HTTPS
The dashboard is pure HTML/CSS/JS. Upload the `public/` folder to any static hosting service.

## ğŸ“ Project Structure

```
crypto-regulatory-tracker/
â”œâ”€â”€ public/                    # Web dashboard (NEW!)
â”‚   â”œâ”€â”€ index.html            # Dashboard UI
â”‚   â””â”€â”€ sample-data.json      # Demo data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ sec.ts            # SEC RSS scraper
â”‚   â”‚   â”œâ”€â”€ esma.ts           # ESMA RSS scraper
â”‚   â”‚   â”œâ”€â”€ mas.ts            # MAS RSS scraper
â”‚   â”‚   â”œâ”€â”€ jfsa.ts           # JFSA HTML scraper
â”‚   â”‚   â”œâ”€â”€ vara.ts           # VARA HTML scraper
â”‚   â”‚   â””â”€â”€ index.ts          # Scraper orchestrator
â”‚   â”œâ”€â”€ classify.ts           # LLM classification
â”‚   â”œâ”€â”€ report.ts             # Report generator
â”‚   â”œâ”€â”€ send.ts               # Email delivery
â”‚   â”œâ”€â”€ db.ts                 # Supabase client
â”‚   â”œâ”€â”€ config.ts             # Configuration
â”‚   â”œâ”€â”€ types.ts              # TypeScript types
â”‚   â”œâ”€â”€ scrape.ts             # Scrape runner
â”‚   â””â”€â”€ index.ts              # Main CLI
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql            # Database schema
â”œâ”€â”€ .env.example
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## Scheduling (Production)

For production, set up cron jobs:

```bash
# Scrape every 6 hours
0 */6 * * * cd /path/to/project && npm run scrape

# Generate report Friday 6pm
0 18 * * 5 cd /path/to/project && npm run dev report

# Send Saturday 9am
0 9 * * 6 cd /path/to/project && npm run dev send
```

Or use Railway/Render scheduled jobs.

## License

MIT
